{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this worksheet is to review the steps involved in *perceptron* training algorithm, and to assess how this method can behave in practical scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step required for both parts, setup the ipython notebook environment to include numpy, scipy, matplotlib etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to use synthetic data. The advantage of using synthetic data is that we have control over the shape of the data, which is useful in studying properties of machine learning methods.\n",
    "\n",
    "We are going to generate data using a function defined below. This function produces S-shaped dataset which is mostly separable, but not necessarily linearly separable. We can control the degree of separability. The resulting dataset is going to be two-dimensional (so that we can plot it) with a binary label. That is, the dataset is a $N\\times2$ array of instances coupled with an $N\\times1$ of labels. The classes are encoded as $-1$ and $1$.\n",
    "\n",
    "Since the dataset is a tuple of two arrays, we are going to use a special data structure called *named tuple* from a Python module called *collections*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def generate_s_shaped_data(gap=3):\n",
    "    x = np.random.randn(80, 2)\n",
    "    x[10:20] += np.array([3, 4])\n",
    "    x[20:30] += np.array([0, 8])\n",
    "    x[30:40] += np.array([3, 12])\n",
    "\n",
    "    x[40:50] += np.array([gap, 0])\n",
    "    x[50:60] += np.array([3 + gap, 4])\n",
    "    x[60:70] += np.array([gap, 8])\n",
    "    x[70:80] += np.array([3 + gap, 12])\n",
    "\n",
    "    t = np.hstack([-np.ones(40), np.ones(40)])\n",
    "    \n",
    "    d = collections.namedtuple('Dataset', ['x', 't'])\n",
    "    d.x = x\n",
    "    d.t = t\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron is a linear classifier. Therefore, we will aim to generate linearly separable data.\n",
    "\n",
    "We start with generating training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.53665140e-01  -6.19033377e-01]\n",
      " [ -9.01640808e-02   8.62865614e-01]\n",
      " [ -1.46128908e+00   1.44954164e-01]\n",
      " [  1.83253994e+00   9.36839163e-01]\n",
      " [ -7.63812784e-01   1.91264225e-01]\n",
      " [ -1.65525473e+00  -2.98203277e-01]\n",
      " [ -5.11910718e-01   1.78315578e-01]\n",
      " [ -3.34730836e+00  -2.22209670e-01]\n",
      " [  1.36227469e-01   1.55328961e+00]\n",
      " [ -4.71614964e-01  -1.98436941e+00]\n",
      " [  3.95712406e+00   5.15781400e+00]\n",
      " [  1.95961676e+00   2.86717094e+00]\n",
      " [  1.04043629e+00   4.73427707e+00]\n",
      " [ -2.10452882e-01   3.79496110e+00]\n",
      " [  3.68477018e+00   2.85817447e+00]\n",
      " [  1.49581696e+00   3.08747363e+00]\n",
      " [  2.13564627e+00   4.39459834e+00]\n",
      " [  1.63089206e+00   4.78497440e+00]\n",
      " [  3.66447484e+00   3.17664156e+00]\n",
      " [  2.39128582e+00   4.67899871e+00]\n",
      " [ -2.29825119e-01   8.07214142e+00]\n",
      " [ -5.68023033e-01   6.45011643e+00]\n",
      " [  4.77064271e-04   8.61194489e+00]\n",
      " [  9.46922548e-01   6.28317124e+00]\n",
      " [  4.32871170e-01   8.12754201e+00]\n",
      " [ -3.01506513e-01   8.65619634e+00]\n",
      " [  1.76914999e-01   8.83004924e+00]\n",
      " [  7.42443692e-01   7.27085126e+00]\n",
      " [  4.00803166e-01   7.58713091e+00]\n",
      " [ -3.69160118e-01   7.84110192e+00]\n",
      " [  2.51353068e+00   1.22929680e+01]\n",
      " [  1.96625049e+00   1.22849436e+01]\n",
      " [  2.07909380e+00   1.18853130e+01]\n",
      " [  3.06396820e+00   1.27828439e+01]\n",
      " [  5.03298970e+00   1.31700393e+01]\n",
      " [  4.42618514e+00   1.36980841e+01]\n",
      " [  4.57965206e+00   1.13586273e+01]\n",
      " [  3.53511425e+00   1.40540997e+01]\n",
      " [  2.98749154e+00   1.40275418e+01]\n",
      " [  2.27167666e+00   1.19511312e+01]\n",
      " [  7.79431305e+00  -5.57136366e-01]\n",
      " [  7.92638419e+00  -9.64010111e-01]\n",
      " [  7.70929131e+00   5.06025117e-01]\n",
      " [  5.92712671e+00  -7.76590909e-01]\n",
      " [  8.48825482e+00  -1.05796580e+00]\n",
      " [  8.80860079e+00  -1.29103615e+00]\n",
      " [  9.55538154e+00   2.02621962e+00]\n",
      " [  6.83961159e+00  -2.77831917e-02]\n",
      " [  8.15448275e+00  -1.50770196e+00]\n",
      " [  9.59455247e+00   1.76012283e+00]\n",
      " [  1.18897727e+01   4.22989380e+00]\n",
      " [  1.23590856e+01   4.56933066e+00]\n",
      " [  1.21705409e+01   2.96930561e+00]\n",
      " [  1.13801395e+01   2.67229025e+00]\n",
      " [  1.18888376e+01   2.79314579e+00]\n",
      " [  1.30660137e+01   3.45117216e+00]\n",
      " [  1.03047363e+01   5.38435177e+00]\n",
      " [  9.86495673e+00   4.60484693e+00]\n",
      " [  1.16713848e+01   4.47302548e+00]\n",
      " [  9.46101257e+00   4.47059020e+00]\n",
      " [  6.17937787e+00   8.89948384e+00]\n",
      " [  8.11491825e+00   9.25564496e+00]\n",
      " [  7.89895067e+00   7.52362059e+00]\n",
      " [  9.80748251e+00   6.99745019e+00]\n",
      " [  7.66699714e+00   1.00651758e+01]\n",
      " [  8.73598993e+00   8.52562414e+00]\n",
      " [  8.57539268e+00   8.03455867e+00]\n",
      " [  7.25138497e+00   9.57039214e+00]\n",
      " [  7.40151412e+00   8.50494418e+00]\n",
      " [  8.65724636e+00   8.53633564e+00]\n",
      " [  1.04291787e+01   1.30309112e+01]\n",
      " [  1.13915725e+01   1.08507137e+01]\n",
      " [  1.01896150e+01   1.16170430e+01]\n",
      " [  1.01448184e+01   1.17558387e+01]\n",
      " [  9.78795953e+00   1.05864367e+01]\n",
      " [  8.99742974e+00   1.18637181e+01]\n",
      " [  1.01504276e+01   1.05594462e+01]\n",
      " [  1.05964219e+01   1.26686293e+01]\n",
      " [  1.20031276e+01   1.11610823e+01]\n",
      " [  1.21485471e+01   1.20762970e+01]]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25708265630>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x257082655f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d  = generate_s_shaped_data(8)\n",
    "print(d.x)\n",
    "print(d.t)\n",
    "x = d.x\n",
    "y = d.t\n",
    "\n",
    "plt.plot(x[y==-1,0], x[y==-1,1], \"o\")\n",
    "plt.plot(x[y==1,0], x[y==1,1], \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will train a binary classifier on this data. For this we’ll use the perceptron algorithm, which\n",
    "you should recall takes a model of the form\n",
    "$$\\begin{align*}\n",
    " s(\\mathbf{x}) &= w_0 + \\mathbf{w}' \\mathbf{x} \\\\\n",
    " predict(\\mathbf{x}) &= \\left\\{ \n",
    "\\begin{array}{cc} \n",
    "1, & \\mbox{if $s(\\mathbf{x}) \\geq 0$} \\\\\n",
    "-1, &  \\mbox{otherwise}\n",
    "\\end{array} \\right .\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will use the standard trick to incorporate the bias term $w_0$ into the weights $\\mathbf{w}$ by using a basis function $\\phi(x_1, x_2) = [1~x_1~x_2]'$ which adds an extra constant dimension. The model becomes\n",
    "$$ s(\\mathbf{x}) = \\mathbf{w}' \\phi(\\mathbf{x}) $$\n",
    "To do this, simply concatenate a column of 1s to the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3) -3.34730836021 14.0540997143\n"
     ]
    }
   ],
   "source": [
    "Phi = np.column_stack([np.ones(x.shape[0]), x])\n",
    "print (Phi.shape, Phi.min(),Phi.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Phi now has $3$ columns. In this array, each training instance is a row and each column is a feature. From now on we will use Phi instead of x. Each row represents $\\phi(\\mathbf{x})$ for a training instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write the prediction function (aka discriminant). This takes as input a data point (a row from Phi, i.e., a vector of 3 numbers) and the model parameters ($\\mathbf{w}$) and outputs predicted label $1$ or $-1$. Recall that if $s(\\mathbf{x})=0$, the predicted class is $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perc_pred(phi, w):\n",
    "#     s = np.dot(phi, w) # over to you\n",
    "    s = np.sign(np.sign(np.dot(phi, w))+0.5)\n",
    "#     s = [1 if x>=0 else -1 for x in s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to test your prediction function with some examples! Note that it's more useful if it can support phi inputs both as vectors (returning a scalar, either +1/-1) and as matrices (returning a vector of +1/-1 values). The latter allows for you to supply a full dataset in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(perc_pred([1, 0, 1], [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(perc_pred(Phi, [1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for training algorithm which fits the weights, $\\mathbf{w}$, to the training data. Recall that this is an online training algorithm, and we are going to iterate through the training examples one by one. Moreover, we are going to do several cycles, called *epochs*, such that we iterate through the entire training set within one epoch. Write a function called *train* which takes the basis data matrix *Phi*, the labels *t* and a number of epochs. This should implement the following pseudo-code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> initialise weights to zero \n",
    "\n",
    "> repeat epoch times\n",
    "\n",
    "> >   for each x and t pair in the training set\n",
    "\n",
    "> > >       if model prediction and y differ, make weight update\n",
    "\n",
    "> return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight update in the inner loop is $\\mathbf{w} \\leftarrow \\mathbf{w} + y \\phi(\\mathbf{x})$.\n",
    "What is the purpose of this update?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, target, epochs, w , eta= 1.):\n",
    "    for e in range(epochs):\n",
    "        for i in range(data.shape[0]):\n",
    "            yhat = perc_pred(data[i,:], w) # over to you?????\n",
    "            if yhat != target[i]:\n",
    "                w = w + np.dot(np.dot(eta,target[i]),data[i]) # over to you\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your training algorithm for 5 epochs to learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.        ,  11.85652637,   3.6810718 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros(Phi.shape[1])\n",
    "w = train(Phi, y, 5, w)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the proportion of misclassified cases as the quality measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "Accuracy = perc_pred(Phi,w)*y # over to you\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun your training with a larger number of epochs (10, 100, 1000), and evaluate how the accuracy changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heldout evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the training data is not a good idea in general, other than for debugging your algorithms. (Can you explain why?) We are going to generate another synthetic data thus essentially creating a fresh *heldout set*. What is the accuracy on this heldout data, and how does this compare to training accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_held = generate_s_shaped_data(8)\n",
    "x_heldout = d_held.x \n",
    "y_heldout = d_held.t\n",
    "\n",
    "\n",
    "plt.plot(x[y==-1,0], x[y==-1,1], \"o\")\n",
    "plt.plot(x[y==1,0], x[y==1,1], \"o\")\n",
    "\n",
    "# plot the heldout data points\n",
    "plt.plot(x_heldout[y_heldout==-1,0], x_heldout[y_heldout==-1,1], \"x\")\n",
    "plt.plot(x_heldout[y_heldout==1,0], x_heldout[y_heldout==1,1], \"x\")\n",
    "\n",
    "\n",
    "Phi_heldout = np.column_stack([np.ones(x_heldout.shape[0]), x_heldout])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the accuracy measure for the held-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = ... # over to you\n",
    "print(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the weights learnt in training. Do these match your intuitions? Plot the decision boundary represented by the weights, $\\mathbf{w}' \\phi(\\mathbf{x}) = 0$. Solving for $x_2$ as a function of $x_1$ yields $x_2 = -\\frac{w_0}{w_2} - \\frac{w_1}{w_2} x_1$. Note that you can *linspace* and *plot* for displaying the line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(0, 6, 100)\n",
    "print(w)\n",
    "x2 = - (w[0] / w[2]) - ((w[1] / w[2]) * x1)\n",
    "\n",
    "\n",
    "\n",
    "# plot the training data points\n",
    "plt.plot(x[y==-1,0], x[y==-1,1], \"o\")\n",
    "plt.plot(x[y==1,0], x[y==1,1], \"o\")\n",
    "\n",
    "# plot the heldout data points\n",
    "plt.plot(x_heldout[y_heldout==-1,0], x_heldout[y_heldout==-1,1], \"x\")\n",
    "plt.plot(x_heldout[y_heldout==1,0], x_heldout[y_heldout==1,1], \"x\")\n",
    "\n",
    "# plot the decision boundary \n",
    "plt.plot(x1, x2)\n",
    "xlabel('x1')\n",
    "ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the decision boundary separate the points in the two classes? Where do you think the decision boundary should go? And how does the boundary change as you train for longer (more epochs)? Plot train and heldout errors as a function of number epochs. Note that careful tuning of the learning rate is needed to get sensible behaviour. Using $\\eta = \\frac{1}{1+e}$ where $e$ is the epoch number often works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hat = np.zeros(Phi.shape[1])\n",
    "T = 60\n",
    "train_error = np.zeros(T)\n",
    "heldout_error = np.zeros(T)\n",
    "for e in range(T):\n",
    "    # here we use a learning rate, which decays with each epoch\n",
    "    lr = 1./(1+e)\n",
    "    w_hat = ... # over to you\n",
    "    \n",
    "    train_error[e] = ... # over to you\n",
    "    heldout_error[e] = ... # over to you\n",
    "\n",
    "plot(train_error, label = 'Train Error')\n",
    "plot(heldout_error, label = 'Held-out Error')\n",
    "plt.legend()\n",
    "xlabel('Epochs')\n",
    "ylabel('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the heldout error track the training error closely? Is the model (i.e., weights at a given epoch) on the training set the same as the best model on the heldout set?\n",
    "\n",
    "Now, let's plot the decision boundary using w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.linspace(2, 10, 100)\n",
    "print(w_hat)\n",
    "x2 = - (w_hat[0] / w_hat[2]) - ((w_hat[1] / w_hat[2]) * x1)\n",
    "\n",
    "# plot the training data points\n",
    "plt.plot(x[y==-1,0], x[y==-1,1], \"o\")\n",
    "plt.plot(x[y==1,0], x[y==1,1], \"o\")\n",
    "\n",
    "# plot the heldout data points\n",
    "plt.plot(x_heldout[y_heldout==-1,0], x_heldout[y_heldout==-1,1], \"x\")\n",
    "plt.plot(x_heldout[y_heldout==1,0], x_heldout[y_heldout==1,1], \"x\")\n",
    "\n",
    "# plot the decision boundary \n",
    "plt.plot(x1, x2)\n",
    "xlabel('x1')\n",
    "ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate training and heldout datasets that are not linearly separable, and investigate what happens to training and heldout errors with increasing number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
